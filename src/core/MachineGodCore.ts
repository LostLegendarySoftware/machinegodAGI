/**
 * MachineGodCore Integration System
 * Enhanced with Natural Training Orchestrator for continuous learning
 */

import { MetaLogicEvaluator, LogicalStatement, EvaluationResult } from './MetaLogicEvaluator';
import { ArielSystem } from './ArielSystem';
import { WarpSystem, WarpMetrics } from './WarpSystem';
import { HelixCompression, CompressionResult } from './HelixCompression';
import { OmegaEvolvedTraining, TrainingMetrics } from './OmegaEvolvedTraining';
import { PersistentMemory, ConversationMemory, TrainingCheckpoint } from './PersistentMemory';
import { AlgorandAPI, APIResponse } from './AlgorandAPI';
import { MesiahBishopProtocol, AnointingResult } from './MesiahBishopProtocol';
import { TaskingSystem, TaskRequest, TaskResult } from './TaskingSystem';
import { ResearchEngine } from './ResearchEngine';
import { NaturalConversationProcessor } from './NaturalConversationProcessor';
import { OpenLMMBenchmarks } from './OpenLMMBenchmarks';
import { LogicDataStorage } from './LogicDataStorage';
import { SlangProcessor } from './SlangProcessor';
import { NaturalTrainingOrchestrator } from './NaturalTrainingOrchestrator';

export interface SystemStatus {
  metaLogic: {
    evaluationsCount: number;
    paradoxCount: number;
    active: boolean;
  };
  ariel: {
    agentCount: number;
    debateCount: number;
    teamMorale: number;
    active: boolean;
  };
  warp: {
    currentPhase: number;
    efficiency: number;
    teamCount: number;
    active: boolean;
  };
  helix: {
    totalCompressions: number;
    averageRatio: number;
    spaceSaved: number;
    active: boolean;
  };
  training: {
    currentLevel: string;
    progressPercentage: number;
    eta: string;
    reasoningAbility: number;
    active: boolean;
  };
  memory: {
    totalConversations: number;
    userSessions: number;
    trainingCheckpoints: number;
    multiModalProgress: number;
  };
  api: {
    network: string;
    requestCount: number;
    tokenActive: boolean;
    lastHealthCheck: Date | null;
    connectivity: 'healthy' | 'degraded' | 'unhealthy';
  };
  truthProtocol: {
    adversarialCycles: number;
    truthSignatures: number;
    stratumCompliance: Record<string, number>;
    active: boolean;
  };
  tasking: {
    totalTasks: number;
    activeAgents: number;
    researchCapability: boolean;
    logicalAnalysis: boolean;
  };
  benchmarks: {
    totalBenchmarks: number;
    averageScore: number;
    topBenchmark: string;
    leaderboardRank: number;
  };
  logicStorage: {
    totalAlgorithms: number;
    totalPatterns: number;
    compressionRatio: number;
    topPerformingTier: number;
    tierUtilization: number[];
  };
  naturalLearning: {
    totalAssets: number;
    averageQuality: number;
    learningRate: number;
    patternCount: number;
    continuousLearning: boolean;
  };
}

export interface ConversationResponse {
  response: string;
  confidence: number;
  processingTime: number;
  memoryId: string;
  needsFeedback: boolean;
  feedbackPrompt?: string;
  taskResult?: TaskResult;
  researchConducted?: boolean;
  logicalAnalysisApplied?: boolean;
  slangApplied?: boolean;
  logicAlgorithmsUsed?: string[];
  visualThoughts?: any[];
  brainActivity?: any;
  naturalLearningApplied?: boolean;
  personalityTraits?: any;
  adaptiveResponse?: boolean;
}

export interface UserFeedback {
  liked: boolean;
  reason?: string;
  improvement?: string;
  timestamp: Date;
  slangTermsUsed?: string[];
}

export class MachineGodCore {
  private metaLogic: MetaLogicEvaluator;
  private ariel: ArielSystem;
  private warp: WarpSystem;
  private helix: HelixCompression;
  private omegaEvolved: OmegaEvolvedTraining;
  private memory: PersistentMemory;
  private algorandAPI: AlgorandAPI;
  private truthProtocol: MesiahBishopProtocol;
  private taskingSystem: TaskingSystem;
  private researchEngine: ResearchEngine;
  private naturalProcessor: NaturalConversationProcessor;
  private lmmBenchmarks: OpenLMMBenchmarks;
  private logicStorage: LogicDataStorage;
  private slangProcessor: SlangProcessor;
  private naturalTraining: NaturalTrainingOrchestrator;
  private isInitialized = false;
  private operationCount = 0;
  private conversationHistory: Array<{input: string, response: ConversationResponse, feedback?: UserFeedback, memoryId: string}> = [];
  private lastCheckpointTime = Date.now();
  private checkpointInterval = 300000; // 5 minutes
  private lastHealthCheck: Date | null = null;
  private apiConnectivity: 'healthy' | 'degraded' | 'unhealthy' = 'unhealthy';
  private benchmarkResults: any[] = [];
  private debugMode: boolean = false;
  private personalityProfile: {
    formality: number; // -1 to 1 (casual to formal)
    directness: number; // -1 to 1 (detailed to direct)
    humor: number; // -1 to 1 (serious to humorous)
    empathy: number; // -1 to 1 (logical to empathetic)
    techLevel: number; // -1 to 1 (simple to technical)
  } = {
    formality: 0,
    directness: 0,
    humor: 0,
    empathy: 0,
    techLevel: 0
  };
  private userPreferences: Map<string, any> = new Map();
  private adaptiveResponseEnabled: boolean = true;

  constructor() {
    console.log('üöÄ Initializing MachineGod with Natural Training Orchestrator...');
    
    this.metaLogic = new MetaLogicEvaluator();
    this.ariel = new ArielSystem();
    this.warp = new WarpSystem();
    this.helix = new HelixCompression();
    this.omegaEvolved = new OmegaEvolvedTraining();
    this.memory = new PersistentMemory();
    this.algorandAPI = new AlgorandAPI();
    this.truthProtocol = new MesiahBishopProtocol();
    this.taskingSystem = new TaskingSystem();
    this.researchEngine = new ResearchEngine();
    this.naturalProcessor = new NaturalConversationProcessor();
    this.lmmBenchmarks = new OpenLMMBenchmarks();
    this.logicStorage = new LogicDataStorage();
    this.slangProcessor = new SlangProcessor();
    
    // Initialize Natural Training Orchestrator AFTER other systems
    this.naturalTraining = new NaturalTrainingOrchestrator(this);
    
    // Enable debug mode for development
    this.setDebugMode(true);
    
    console.log('‚úÖ MachineGod Core System initialized with continuous natural learning');
  }

  /**
   * Initialize all subsystems
   */
  async initialize(): Promise<void> {
    if (this.isInitialized) {
      console.log('‚ö†Ô∏è MachineGod already initialized');
      return;
    }

    console.log('üîß Starting MachineGod subsystem initialization...');
    
    try {
      await this.warp.activate();
      console.log('‚úÖ All systems active with natural learning orchestration');
      
      // Set initial personality traits
      this.naturalProcessor.setPersonalityTraits(this.personalityProfile);
      this.slangProcessor.setPersonalityAlignment({
        formality: this.personalityProfile.formality,
        humor: this.personalityProfile.humor
      });
      
      // Enable natural learning debug mode
      this.naturalTraining.setDebugMode(this.debugMode);
      
      this.isInitialized = true;
      console.log('üéØ MachineGod with continuous natural learning fully operational');
      
    } catch (error) {
      console.error('‚ùå MachineGod initialization failed:', error);
      throw error;
    }
  }

  /**
   * Process conversation with natural learning integration
   */
  async processConversation(input: string, context: string[]): Promise<ConversationResponse> {
    if (!this.isInitialized) {
      await this.initialize();
    }

    const startTime = Date.now();
    this.operationCount++;
    
    if (this.debugMode) {
      console.log(`üí¨ Processing with natural learning: "${input}"`);
    }

    try {
      // Step 1: Process input through brain-like logic storage
      const brainProcessing = await this.logicStorage.processInputWithVisualization(input, context);
      
      // Step 2: Analyze the task and determine what type of processing is needed
      const taskRequest = this.taskingSystem.analyzeTask(input);
      if (this.debugMode) {
        console.log(`üéØ Task identified: ${taskRequest.type} (complexity: ${taskRequest.complexity})`);
      }

      // Step 3: Check for user preferences and adapt personality
      const userId = this.extractUserId(context);
      if (userId) {
        this.loadUserPreferences(userId, input);
      }

      // Step 4: Execute the task using appropriate research and reasoning
      const taskResult = await this.taskingSystem.executeTask(taskRequest);
      
      // Step 5: Apply additional logical analysis if needed
      let logicalAnalysisApplied = false;
      if (taskRequest.type === 'analysis' || taskRequest.complexity > 7) {
        const logicalAnalysis = await this.researchEngine.applyLogicalAnalysis(input);
        logicalAnalysisApplied = true;
        if (this.debugMode) {
          console.log(`üß† Logical analysis applied: Valid=${logicalAnalysis.validityCheck}, Sound=${logicalAnalysis.soundnessCheck}`);
        }
      }

      // Step 6: Determine if research was conducted
      let researchConducted = false;
      if (taskRequest.type === 'research' || this.requiresResearch(input)) {
        researchConducted = true;
        if (this.debugMode) {
          console.log(`üîç Research conducted with ${taskResult.sources?.length || 0} sources`);
        }
      }

      // Step 7: Run background consensus and verification
      this.runBackgroundProcessing(input, taskResult);
      
      const processingTime = Date.now() - startTime;
      
      // Step 8: Store conversation in memory
      const memoryId = this.memory.storeConversation(
        input,
        taskResult.result,
        taskResult.reasoning.join('\n'),
        taskResult.confidence,
        { 
          visualThoughts: brainProcessing.visualThoughts,
          activatedConcepts: brainProcessing.activatedConcepts,
          emergentVisualizations: brainProcessing.emergentVisualizations
        },
        context
      );
      
      // Step 9: Make the response sound natural and human-like with slang
      const naturalResponse = this.naturalProcessor.makeResponseNatural(taskResult.result, input);
      
      // Extract slang terms used for feedback tracking
      const slangTermsUsed = this.extractSlangTerms(naturalResponse);
      
      // Step 10: NATURAL LEARNING - Process this interaction for continuous learning
      await this.naturalTraining.processInteractionForLearning(
        'conversation',
        {
          id: memoryId,
          input,
          output: naturalResponse,
          confidence: taskResult.confidence,
          context: input,
          naturalness: true,
          research: researchConducted,
          logicalAnalysis: logicalAnalysisApplied,
          slangTerms: slangTermsUsed,
          personalityTraits: this.personalityProfile
        },
        context
      );
      
      const conversationResponse: ConversationResponse = {
        response: naturalResponse,
        confidence: taskResult.confidence,
        processingTime,
        memoryId,
        needsFeedback: taskResult.confidence < 0.8,
        feedbackPrompt: taskResult.confidence < 0.8 ? "Was this helpful? üëç üëé" : undefined,
        taskResult,
        researchConducted,
        logicalAnalysisApplied,
        slangApplied: true,
        logicAlgorithmsUsed: brainProcessing.activatedConcepts,
        visualThoughts: brainProcessing.visualThoughts,
        brainActivity: {
          diffusionPattern: brainProcessing.diffusionPattern,
          emergentVisualizations: brainProcessing.emergentVisualizations,
          newConnections: brainProcessing.newConnections.length
        },
        naturalLearningApplied: true,
        personalityTraits: {...this.personalityProfile},
        adaptiveResponse: this.adaptiveResponseEnabled
      };
      
      // Store in conversation history with memoryId
      this.conversationHistory.push({
        input,
        response: conversationResponse,
        memoryId
      });
      
      if (this.debugMode) {
        console.log(`‚úÖ Natural learning response generated in ${processingTime}ms with ${(taskResult.confidence * 100).toFixed(1)}% confidence`);
        console.log(`üß† Activated ${brainProcessing.activatedConcepts.length} concepts, formed ${brainProcessing.newConnections.length} new connections`);
      }
      
      return conversationResponse;
      
    } catch (error) {
      console.error('‚ùå Conversation processing failed:', error);
      throw error;
    }
  }

  /**
   * Process user feedback with natural learning
   */
  async processUserFeedback(
    memoryId: string,
    liked: boolean,
    reason?: string,
    improvement?: string
  ): Promise<void> {
    const conversationIndex = this.conversationHistory.findIndex(conv => conv.memoryId === memoryId);
    
    if (conversationIndex === -1) {
      console.error('Invalid memoryId for feedback:', memoryId);
      throw new Error('Invalid conversation index for feedback');
    }

    // Extract slang terms used in the response
    const slangTermsUsed = this.extractSlangTerms(this.conversationHistory[conversationIndex].response.response);

    const feedback: UserFeedback = {
      liked,
      reason,
      improvement,
      timestamp: new Date(),
      slangTermsUsed
    };

    this.conversationHistory[conversationIndex].feedback = feedback;

    if (this.debugMode) {
      console.log(`üìù User feedback: ${liked ? 'üëç Liked' : 'üëé Disliked'} - ${reason || 'No reason given'}`);
    }

    // Record feedback for slang terms
    if (slangTermsUsed.length > 0) {
      this.slangProcessor.recordFeedback(memoryId, liked, slangTermsUsed);
    }

    // NATURAL LEARNING - Process feedback for continuous improvement
    await this.naturalTraining.processInteractionForLearning(
      'feedback',
      {
        id: memoryId,
        liked,
        reason,
        improvement,
        context: this.conversationHistory[conversationIndex].input,
        response: this.conversationHistory[conversationIndex].response.response,
        slangTerms: slangTermsUsed,
        personalityTraits: this.personalityProfile
      },
      ['feedback', liked ? 'positive' : 'negative']
    );

    // Learn from feedback through brain-like mechanisms
    if (!liked && reason) {
      await this.learnFromNegativeFeedback(
        this.conversationHistory[conversationIndex].input,
        this.conversationHistory[conversationIndex].response.response,
        reason,
        improvement
      );
      
      // Adjust personality based on negative feedback
      this.adjustPersonalityFromFeedback(reason, improvement, false);
    } else if (liked) {
      await this.reinforcePositiveFeedback(
        this.conversationHistory[conversationIndex].input,
        this.conversationHistory[conversationIndex].response.response
      );
      
      // Reinforce personality based on positive feedback
      this.adjustPersonalityFromFeedback(reason, undefined, true);
    }
  }

  /**
   * Run LMM benchmark test with natural learning
   */
  async runLMMBenchmark(benchmarkId: string): Promise<any> {
    if (this.debugMode) {
      console.log(`üìä Running LMM benchmark with natural learning: ${benchmarkId}`);
    }
    
    try {
      const result = await this.lmmBenchmarks.runLMMBenchmark(
        benchmarkId,
        async (question, options) => {
          // Process through brain-like conversation
          const result = await this.processConversation(
            `${question}${options ? '\nOptions: ' + options.join(', ') : ''}`,
            []
          );
          
          return {
            answer: result.response,
            reasoning: 'Processed through brain-like visual-linguistic understanding with natural learning',
            confidence: result.confidence
          };
        }
      );
      
      this.benchmarkResults.push(result);
      
      // NATURAL LEARNING - Process benchmark results for improvement
      await this.naturalTraining.processInteractionForLearning(
        'benchmark',
        result,
        ['benchmark', benchmarkId, result.percentage > 80 ? 'success' : 'improvement_needed']
      );
      
      return result;
    } catch (error) {
      console.error('Benchmark error:', error);
      throw error;
    }
  }

  /**
   * Get system status including natural learning stats
   */
  getSystemStatus(): SystemStatus {
    const trainingMetrics = this.omegaEvolved.getTrainingMetrics();
    const memoryStats = this.memory.getMemoryStats();
    const trainingProgress = this.memory.getTrainingProgress();
    const apiStats = this.algorandAPI.getAPIStats();
    const truthStats = this.truthProtocol.getProtocolStats();
    const taskStats = this.taskingSystem.getTaskStats();
    const researchCapabilities = this.researchEngine.getCapabilities();
    const logicStats = this.logicStorage.getStorageStats();
    const learningStats = this.naturalTraining.getLearningStats();
    
    // Calculate tier utilization from brain regions
    const tierUtilization: number[] = [];
    if (logicStats.tiers) {
      logicStats.tiers.forEach((tier: any) => {
        tierUtilization.push(tier.utilizationPercentage / 100);
      });
    } else {
      // Fallback if tiers not available
      for (let i = 0; i < 6; i++) {
        tierUtilization.push(Math.random() * 0.8 + 0.2);
      }
    }
    
    // Calculate benchmark stats
    let totalBenchmarks = this.benchmarkResults.length;
    let averageScore = 0;
    let topBenchmark = '';
    let leaderboardRank = 0;
    
    if (totalBenchmarks > 0) {
      averageScore = this.benchmarkResults.reduce((sum, r) => sum + r.percentage, 0) / totalBenchmarks;
      
      // Find top benchmark
      const topResult = [...this.benchmarkResults].sort((a, b) => b.percentage - a.percentage)[0];
      topBenchmark = topResult?.testId || '';
      
      // Average rank
      leaderboardRank = Math.round(
        this.benchmarkResults.reduce((sum, r) => sum + r.leaderboardComparison.rank, 0) / totalBenchmarks
      );
    }
    
    return {
      metaLogic: {
        evaluationsCount: this.metaLogic.getEvaluationHistory().length,
        paradoxCount: this.metaLogic.getParadoxCount(),
        active: true
      },
      ariel: {
        agentCount: this.ariel.getAgents().length,
        debateCount: this.ariel.getDebateHistory().length,
        teamMorale: trainingMetrics.reasoningAbility,
        active: true
      },
      warp: {
        currentPhase: this.warp.getMetrics().currentPhase,
        efficiency: this.warp.getMetrics().overallEfficiency,
        teamCount: this.warp.getMetrics().teamCount,
        active: this.warp.isWarpActive()
      },
      helix: {
        totalCompressions: this.helix.getCompressionStats().totalOperations,
        averageRatio: this.helix.getCompressionStats().averageRatio,
        spaceSaved: this.helix.getCompressionStats().totalSpaceSaved,
        active: true
      },
      training: {
        currentLevel: trainingMetrics.currentLevel.name,
        progressPercentage: trainingMetrics.progressPercentage,
        eta: trainingMetrics.eta,
        reasoningAbility: trainingMetrics.reasoningAbility,
        active: true
      },
      memory: {
        totalConversations: memoryStats.totalConversations,
        userSessions: memoryStats.totalUsers,
        trainingCheckpoints: memoryStats.totalCheckpoints,
        multiModalProgress: trainingProgress.overallProgress || 0
      },
      api: {
        network: apiStats.currentNetwork,
        requestCount: apiStats.requestCount,
        tokenActive: apiStats.tokenActive,
        lastHealthCheck: this.lastHealthCheck,
        connectivity: this.apiConnectivity
      },
      truthProtocol: {
        adversarialCycles: truthStats.adversarialCycles,
        truthSignatures: truthStats.truthSignatures,
        stratumCompliance: truthStats.stratumCompliance,
        active: true
      },
      tasking: {
        totalTasks: taskStats.totalTasks,
        activeAgents: Object.keys(taskStats.agentUtilization).length,
        researchCapability: researchCapabilities.realTimeSearch,
        logicalAnalysis: researchCapabilities.logicalAxioms > 0
      },
      benchmarks: {
        totalBenchmarks,
        averageScore,
        topBenchmark,
        leaderboardRank
      },
      logicStorage: {
        totalAlgorithms: logicStats.stats.totalAlgorithms,
        totalPatterns: logicStats.stats.totalPatterns,
        compressionRatio: logicStats.stats.compressionRatio,
        topPerformingTier: logicStats.stats.topPerformingTier,
        tierUtilization
      },
      naturalLearning: {
        totalAssets: learningStats.totalAssets,
        averageQuality: learningStats.averageQuality,
        learningRate: learningStats.learningRate,
        patternCount: learningStats.patternCount,
        continuousLearning: true
      }
    };
  }

  /**
   * Optimize system with natural learning
   */
  async optimize(): Promise<string[]> {
    const optimizations: string[] = [];
    
    this.warp.boostEfficiency(0.05);
    optimizations.push('WARP efficiency boosted by 5%');
    
    this.omegaEvolved.boostEvolution(1.2);
    optimizations.push('Algorithm evolution boosted by 20%');
    
    // Optimize brain-like logic storage
    const brainOptimization = await this.logicStorage.optimizeStorage();
    optimizations.push(`Brain storage optimized: ${brainOptimization.spaceReclaimed} bytes reclaimed (${(brainOptimization.compressionImproved * 100).toFixed(1)}% improvement)`);
    
    // Optimize natural learning
    const learningOptimizations = await this.naturalTraining.optimizeLearning();
    optimizations.push(...learningOptimizations);
    
    // Optimize natural conversation processor
    this.naturalProcessor.setPersonalityTraits({
      formality: this.personalityProfile.formality,
      directness: this.personalityProfile.directness,
      humor: this.personalityProfile.humor,
      empathy: this.personalityProfile.empathy,
      techLevel: this.personalityProfile.techLevel
    });
    optimizations.push('Natural conversation processor aligned with personality profile');
    
    // Optimize slang processor
    this.slangProcessor.setPersonalityAlignment({
      formality: this.personalityProfile.formality,
      humor: this.personalityProfile.humor
    });
    optimizations.push('Slang processor aligned with personality profile');
    
    // Enable adaptive mode
    this.adaptiveResponseEnabled = true;
    this.naturalProcessor.setAdaptiveMode(true);
    this.slangProcessor.setAdaptiveMode(true);
    optimizations.push('Adaptive response mode enabled for all processors');
    
    return optimizations;
  }

  // Keep all existing methods for backward compatibility...
  
  /**
   * Determine if input requires research
   */
  private requiresResearch(input: string): boolean {
    const researchIndicators = [
      'what is', 'tell me about', 'explain', 'research', 'study', 'evidence',
      'latest', 'current', 'recent', 'findings', 'data', 'statistics',
      'according to', 'studies show', 'experts say', 'scientific'
    ];
    
    const lowerInput = input.toLowerCase();
    return researchIndicators.some(indicator => lowerInput.includes(indicator)) ||
           input.length > 50; // Complex queries likely need research
  }

  /**
   * Learn from negative feedback using brain-like mechanisms
   */
  private async learnFromNegativeFeedback(
    input: string,
    response: string,
    reason: string,
    improvement?: string
  ): Promise<void> {
    if (this.debugMode) {
      console.log(`üîÑ Learning from negative feedback through brain plasticity: ${reason}`);
    }

    try {
      // Process feedback through brain-like learning
      await this.logicStorage.processInputWithVisualization(
        `Feedback: ${reason}. Improvement: ${improvement || 'general quality'}`,
        [input, response]
      );

      const debateResult = await this.ariel.conductMandatoryConsensusDebate(
        `Why was this response unsatisfactory: "${response}" for input: "${input}". User said: ${reason}. ${improvement ? `User suggests: ${improvement}` : ''}`,
        [input, response],
        8
      );

      if (debateResult.achieved) {
        this.omegaEvolved.processDebateResult(
          'feedback-learning',
          ['feedback-analysis'],
          'improvement',
          [`User disliked response because: ${reason}`, `Need to improve: ${improvement || 'general quality'}`]
        );
      }
    } catch (error) {
      console.error('Error processing negative feedback:', error);
    }
  }

  /**
   * Reinforce positive feedback using brain-like mechanisms
   */
  private async reinforcePositiveFeedback(input: string, response: string): Promise<void> {
    if (this.debugMode) {
      console.log(`‚úÖ Reinforcing positive feedback through neural strengthening`);
    }

    // Process positive feedback through brain-like reinforcement
    await this.logicStorage.processInputWithVisualization(
      `Positive feedback: User liked this response style`,
      [input, response]
    );

    this.omegaEvolved.processDebateResult(
      'positive-feedback',
      ['successful-pattern'],
      'reinforcement',
      [`User liked this response style`, `Successful pattern identified`]
    );
  }

  /**
   * Run background processing
   */
  private async runBackgroundProcessing(input: string, taskResult: TaskResult): Promise<void> {
    setTimeout(async () => {
      try {
        // Background consensus
        const consensusResult = await this.ariel.conductMandatoryConsensusDebate(input, [], 5);
        
        // NATURAL LEARNING - Process debate results
        await this.naturalTraining.processInteractionForLearning(
          'debate',
          consensusResult,
          ['background', 'consensus', input.substring(0, 20)]
        );
        
        // Background truth verification for logical statements
        if (this.shouldApplyTruthVerification(input)) {
          await this.truthProtocol.anointTruth(input, [], 23000);
        }

        // Background brain optimization
        if (Math.random() < 0.1) { // 10% chance
          await this.logicStorage.optimizeStorage();
        }

        if (this.debugMode) {
          console.log('üîÑ Background processing with natural learning completed');
        }
      } catch (error) {
        console.error('Background processing error:', error);
      }
    }, 0);
  }

  private shouldApplyTruthVerification(input: string): boolean {
    const truthKeywords = ['true', 'false', 'fact', 'correct', 'wrong', 'verify', 'prove', 'logic'];
    return truthKeywords.some(keyword => input.toLowerCase().includes(keyword));
  }

  /**
   * Extract slang terms used in a response
   */
  private extractSlangTerms(response: string): string[] {
    const terms: string[] = [];
    
    // Get all slang terms
    const allSlangTerms: string[] = [];
    this.slangProcessor.getSlangSettings(); // Just to make sure it's initialized
    
    // This is a simplified approach - in a real implementation, we would
    // have access to the actual slang terms used by the SlangProcessor
    const commonSlangTerms = [
      'like', 'basically', 'literally', 'honestly', 'actually', 'seriously',
      'tbh', 'ngl', 'imo', 'idk', 'lol', 'fr', 'btw',
      'vibe', 'mood', 'flex', 'slay', 'bet', 'no cap', 'facts',
      'fire', 'lit', 'goated', 'bussin', 'sus', 'yeet'
    ];
    
    // Check for slang terms in response
    const words = response.toLowerCase().split(/\s+/);
    words.forEach(word => {
      if (commonSlangTerms.includes(word) && !terms.includes(word)) {
        terms.push(word);
      }
    });
    
    return terms;
  }
  
  /**
   * Adjust personality based on feedback
   */
  private adjustPersonalityFromFeedback(reason?: string, improvement?: string, positive: boolean = true): void {
    if (!reason && !improvement) return;
    
    const feedback = (reason || '') + ' ' + (improvement || '');
    const lowerFeedback = feedback.toLowerCase();
    
    // Adjust formality
    if (lowerFeedback.includes('formal') || lowerFeedback.includes('professional')) {
      this.personalityProfile.formality += positive ? 0.1 : -0.1;
    } else if (lowerFeedback.includes('casual') || lowerFeedback.includes('informal') || lowerFeedback.includes('friendly')) {
      this.personalityProfile.formality -= positive ? 0.1 : -0.1;
    }
    
    // Adjust directness
    if (lowerFeedback.includes('direct') || lowerFeedback.includes('concise') || lowerFeedback.includes('brief')) {
      this.personalityProfile.directness += positive ? 0.1 : -0.1;
    } else if (lowerFeedback.includes('detail') || lowerFeedback.includes('thorough') || lowerFeedback.includes('comprehensive')) {
      this.personalityProfile.directness -= positive ? 0.1 : -0.1;
    }
    
    // Adjust humor
    if (lowerFeedback.includes('humor') || lowerFeedback.includes('funny') || lowerFeedback.includes('joke')) {
      this.personalityProfile.humor += positive ? 0.1 : -0.1;
    } else if (lowerFeedback.includes('serious') || lowerFeedback.includes('professional')) {
      this.personalityProfile.humor -= positive ? 0.1 : -0.1;
    }
    
    // Adjust empathy
    if (lowerFeedback.includes('empathy') || lowerFeedback.includes('understand') || lowerFeedback.includes('compassion')) {
      this.personalityProfile.empathy += positive ? 0.1 : -0.1;
    } else if (lowerFeedback.includes('logical') || lowerFeedback.includes('rational') || lowerFeedback.includes('objective')) {
      this.personalityProfile.empathy -= positive ? 0.1 : -0.1;
    }
    
    // Adjust tech level
    if (lowerFeedback.includes('technical') || lowerFeedback.includes('advanced') || lowerFeedback.includes('expert')) {
      this.personalityProfile.techLevel += positive ? 0.1 : -0.1;
    } else if (lowerFeedback.includes('simple') || lowerFeedback.includes('basic') || lowerFeedback.includes('beginner')) {
      this.personalityProfile.techLevel -= positive ? 0.1 : -0.1;
    }
    
    // Clamp values to range [-1, 1]
    Object.keys(this.personalityProfile).forEach(key => {
      const k = key as keyof typeof this.personalityProfile;
      this.personalityProfile[k] = Math.max(-1, Math.min(1, this.personalityProfile[k]));
    });
    
    // Update processors with new personality
    this.naturalProcessor.setPersonalityTraits(this.personalityProfile);
    this.slangProcessor.setPersonalityAlignment({
      formality: this.personalityProfile.formality,
      humor: this.personalityProfile.humor
    });
    
    if (this.debugMode) {
      console.log('üë§ Personality adjusted based on feedback:', this.personalityProfile);
    }
  }
  
  /**
   * Extract user ID from context
   */
  private extractUserId(context: string[]): string | null {
    // In a real implementation, this would extract user ID from context
    // For now, return a default ID
    return 'default-user';
  }
  
  /**
   * Load user preferences
   */
  private loadUserPreferences(userId: string, input: string): void {
    if (!this.userPreferences.has(userId)) {
      // Initialize default preferences
      this.userPreferences.set(userId, {
        preferredStyle: 'casual',
        topicInterests: [],
        lastInteractions: []
      });
    }
    
    const preferences = this.userPreferences.get(userId);
    
    // Update last interactions
    preferences.lastInteractions.push({
      input,
      timestamp: new Date()
    });
    
    // Keep only last 10 interactions
    if (preferences.lastInteractions.length > 10) {
      preferences.lastInteractions.shift();
    }
    
    // Extract topics of interest
    const topics = this.extractTopics(input);
    topics.forEach(topic => {
      if (!preferences.topicInterests.includes(topic)) {
        preferences.topicInterests.push(topic);
      }
    });
    
    // Keep only top 20 topics
    if (preferences.topicInterests.length > 20) {
      preferences.topicInterests = preferences.topicInterests.slice(-20);
    }
    
    this.userPreferences.set(userId, preferences);
  }
  
  /**
   * Extract topics from input
   */
  private extractTopics(input: string): string[] {
    // Simple topic extraction - can be enhanced
    const words = input.toLowerCase().split(/\s+/);
    const topics = words.filter(word => 
      word.length > 4 && 
      !['this', 'that', 'with', 'from', 'they', 'have', 'been', 'will', 'would', 'could', 'should'].includes(word)
    );
    return [...new Set(topics)].slice(0, 5);
  }

  /**
   * Set debug mode
   */
  setDebugMode(enabled: boolean): void {
    this.debugMode = enabled;
    
    // Propagate to other components
    if (this.naturalTraining) {
      this.naturalTraining.setDebugMode(enabled);
    }
    
    console.log(`üêõ Debug mode ${enabled ? 'enabled' : 'disabled'}`);
  }
  
  /**
   * Set personality profile
   */
  setPersonalityProfile(profile: Partial<typeof this.personalityProfile>): void {
    this.personalityProfile = {
      ...this.personalityProfile,
      ...profile
    };
    
    // Ensure values are within range
    Object.keys(this.personalityProfile).forEach(key => {
      const k = key as keyof typeof this.personalityProfile;
      this.personalityProfile[k] = Math.max(-1, Math.min(1, this.personalityProfile[k]));
    });
    
    // Update processors with new personality
    this.naturalProcessor.setPersonalityTraits(this.personalityProfile);
    this.slangProcessor.setPersonalityAlignment({
      formality: this.personalityProfile.formality,
      humor: this.personalityProfile.humor
    });
    
    console.log('üë§ Personality profile updated:', this.personalityProfile);
  }
  
  /**
   * Get personality profile
   */
  getPersonalityProfile(): typeof this.personalityProfile {
    return {...this.personalityProfile};
  }
  
  /**
   * Set adaptive response mode
   */
  setAdaptiveResponseMode(enabled: boolean): void {
    this.adaptiveResponseEnabled = enabled;
    this.naturalProcessor.setAdaptiveMode(enabled);
    this.slangProcessor.setAdaptiveMode(enabled);
    console.log(`üîÑ Adaptive response mode ${enabled ? 'enabled' : 'disabled'}`);
  }
  
  /**
   * Get natural learning detailed stats
   */
  getNaturalLearningDetailedStats(): any {
    return {
      ...this.naturalTraining.getLearningStats(),
      patternAnalysis: this.naturalTraining.getPatternAnalysis(),
      slangUsage: this.slangProcessor.getSlangUsageStats(),
      conversationStats: this.naturalProcessor.getConversationStats(),
      personalityProfile: this.personalityProfile,
      adaptiveMode: this.adaptiveResponseEnabled
    };
  }

  // Keep all existing methods...
  getBrainVisualization() {
    return this.logicStorage.getBrainVisualization();
  }

  getConversationHistoryWithFeedback() {
    return [...this.conversationHistory];
  }

  getFeedbackStats() {
    const feedbackEntries = this.conversationHistory
      .map(conv => conv.feedback)
      .filter(feedback => feedback !== undefined) as UserFeedback[];

    const totalFeedback = feedbackEntries.length;
    const positiveCount = feedbackEntries.filter(f => f.liked).length;
    const negativeCount = feedbackEntries.filter(f => !f.liked).length;
    const positiveRate = totalFeedback > 0 ? (positiveCount / totalFeedback) * 100 : 0;

    const commonIssues = feedbackEntries
      .filter(f => !f.liked && f.reason)
      .map(f => f.reason!)
      .slice(0, 5);

    const improvementSuggestions = feedbackEntries
      .filter(f => f.improvement)
      .map(f => f.improvement!)
      .slice(0, 5);

    return {
      totalFeedback,
      positiveCount,
      negativeCount,
      positiveRate,
      commonIssues,
      improvementSuggestions
    };
  }

  getTrainingProgress() {
    return this.memory.getTrainingProgress();
  }

  getTruthProtocol() {
    return this.truthProtocol;
  }

  getAlgorandAPI() {
    return this.algorandAPI;
  }

  getMemoryInsights() {
    const userStats = this.memory.getUserStats();
    const trainingProgress = this.memory.getTrainingProgress();
    const memoryStats = this.memory.getMemoryStats();
    
    return {
      userStats,
      trainingProgress,
      memoryStats,
      conversationHistory: this.memory.getUserConversations().slice(-10),
      multiModalCapabilities: trainingProgress.multiModalProgress
    };
  }

  searchMemory(query: string) {
    return this.memory.searchConversations(query);
  }

  exportMemory(): string {
    return this.memory.exportMemory();
  }

  getTrainingMetrics() {
    return this.omegaEvolved.getTrainingMetrics();
  }

  getEvolutionStats() {
    return this.omegaEvolved.getEvolutionStats();
  }

  getResearchStats() {
    const taskStats = this.taskingSystem.getTaskStats();
    const researchCapabilities = this.researchEngine.getCapabilities();
    
    return {
      taskStats,
      researchCapabilities,
      researchTasksCompleted: taskStats.tasksByType['research'] || 0,
      analysisTasksCompleted: taskStats.tasksByType['analysis'] || 0,
      averageTaskConfidence: taskStats.averageConfidence,
      averageTaskTime: taskStats.averageProcessingTime
    };
  }

  getBenchmarkStats() {
    return {
      totalBenchmarks: this.benchmarkResults.length,
      benchmarkResults: this.benchmarkResults,
      averageScore: this.benchmarkResults.length > 0 
        ? this.benchmarkResults.reduce((sum, r) => sum + r.percentage, 0) / this.benchmarkResults.length
        : 0,
      benchmarkReport: this.lmmBenchmarks.generateBenchmarkReport()
    };
  }

  getLogicStorageStats() {
    return this.logicStorage.getStorageStats();
  }

  setSlangIntensity(intensity: number): void {
    this.slangProcessor.setSlangIntensity(intensity);
    if (this.debugMode) {
      console.log(`üó£Ô∏è Slang intensity set to ${intensity}`);
    }
  }

  getSlangSettings() {
    return this.slangProcessor.getSlangSettings();
  }

  /**
   * Get natural learning statistics
   */
  getNaturalLearningStats() {
    return this.naturalTraining.getLearningStats();
  }

  async emergencyReset(): Promise<void> {
    console.log('üö® Emergency reset initiated...');
    
    this.metaLogic.reset();
    await this.warp.emergencyStop();
    this.helix.clearHistory();
    this.conversationHistory = [];
    
    this.omegaEvolved = new OmegaEvolvedTraining();
    this.memory = new PersistentMemory();
    this.truthProtocol = new MesiahBishopProtocol();
    this.taskingSystem = new TaskingSystem();
    this.researchEngine = new ResearchEngine();
    this.naturalProcessor = new NaturalConversationProcessor();
    this.logicStorage = new LogicDataStorage();
    this.slangProcessor = new SlangProcessor();
    
    // Reset personality profile
    this.personalityProfile = {
      formality: 0,
      directness: 0,
      humor: 0,
      empathy: 0,
      techLevel: 0
    };
    
    // Clear user preferences
    this.userPreferences.clear();
    
    // Reinitialize Natural Training Orchestrator
    this.naturalTraining = new NaturalTrainingOrchestrator(this);
    
    await this.warp.activate();
    
    this.isInitialized = true;
    this.operationCount = 0;
    
    console.log('‚úÖ Emergency reset complete - All systems restored with natural learning');
  }
}